{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ec44bc",
   "metadata": {},
   "source": [
    "Code to understand the Duke-WLOA AMD dataset better \n",
    "\n",
    "- understand reading Image annotations. Otherwise explore reading .mat files\n",
    "- how converting image data into numpy arrays work\n",
    "- how to generate embeddings\n",
    "    - which data type to use for this task\n",
    "    - which model to use?\n",
    "    - what are the steps for generating image embeddings\n",
    "    - how does the model architecture look like for this task\n",
    "- Write the code\n",
    "- Store embeddings as pytorch arrays\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a13287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63428cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image_path = '/home/suraj/Data/Duke_WLOA_RL_Annotated/AMD_PNG/layer/AMD_001_024.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was loaded successfully\n",
    "if image is None:\n",
    "    print(\"Error: Could not load the image. Check the file path.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3410103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image from BGR (OpenCV default) to RGB\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique colors in the image\n",
    "unique_colors = np.unique(image_rgb.reshape(-1, image_rgb.shape[2]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00dbc87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50861/1291825849.py:2: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  colored_annotations = [color for color in unique_colors if not (abs(color[0] - color[1]) < 10 and abs(color[1] - color[2]) < 10)]\n"
     ]
    }
   ],
   "source": [
    "# Filter out grayscale colors (where R ≈ G ≈ B) to focus on annotations\n",
    "colored_annotations = [color for color in unique_colors if not (abs(color[0] - color[1]) < 10 and abs(color[1] - color[2]) < 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eadf7725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50861/3331092312.py:8: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  abs(color[1] - main_color[1]) < tolerance and\n",
      "/tmp/ipykernel_50861/3331092312.py:9: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  abs(color[2] - main_color[2]) < tolerance):\n"
     ]
    }
   ],
   "source": [
    "# Group similar colors into 3 clusters based on RGB proximity (simple tolerance)\n",
    "tolerance = 20  # Adjust this value if needed\n",
    "main_colors = []\n",
    "for color in colored_annotations:\n",
    "    matched = False\n",
    "    for main_color in main_colors:\n",
    "        if (abs(color[0] - main_color[0]) < tolerance and\n",
    "            abs(color[1] - main_color[1]) < tolerance and\n",
    "            abs(color[2] - main_color[2]) < tolerance):\n",
    "            matched = True\n",
    "            break\n",
    "    if not matched:\n",
    "        main_colors.append(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d85aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to 3 main colors (assuming 3 layers)\n",
    "main_colors = main_colors[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deabb0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected colored annotations (3 main layers):\n",
      "Layer 1: RGB = (np.uint8(0), np.uint8(128), np.uint8(0)), Hex = #008000\n",
      "Layer 2: RGB = (np.uint8(3), np.uint8(121), np.uint8(3)), Hex = #037903\n",
      "Layer 3: RGB = (np.uint8(5), np.uint8(5), np.uint8(242)), Hex = #0505f2\n"
     ]
    }
   ],
   "source": [
    "# Print the color codes (RGB and Hex) for the 3 main annotations\n",
    "print(\"Detected colored annotations (3 main layers):\")\n",
    "for i, color in enumerate(main_colors, 1):\n",
    "    rgb = (color[0], color[1], color[2])\n",
    "    hex_code = '#{:02x}{:02x}{:02x}'.format(color[0], color[1], color[2])\n",
    "    print(f\"Layer {i}: RGB = {rgb}, Hex = {hex_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b97cb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected colored annotations (3 main layers):\n",
      "Layer 1 (expected red): RGB = (np.int64(99), np.int64(99), np.int64(99)), Hex = #636363\n",
      "Layer 2 (expected green): RGB = (np.int64(74), np.int64(74), np.int64(74)), Hex = #4a4a4a\n",
      "Layer 3 (expected blue): RGB = (np.int64(42), np.int64(42), np.int64(42)), Hex = #2a2a2a\n"
     ]
    }
   ],
   "source": [
    "# Define regions for each layer (approximate y-coordinates based on the image)\n",
    "height = image_rgb.shape[0]\n",
    "top_layer_y = int(height * 0.3)    # Top third for red layer\n",
    "mid_layer_y = int(height * 0.5)    # Middle for green layer\n",
    "bottom_layer_y = int(height * 0.7) # Bottom third for blue layer\n",
    "\n",
    "# Sample colors from each region (average over a small horizontal strip)\n",
    "def get_layer_color(y_pos, width_range=50):\n",
    "    start_x = image_rgb.shape[1] // 2 - width_range // 2\n",
    "    end_x = start_x + width_range\n",
    "    strip = image_rgb[y_pos-2:y_pos+2, start_x:end_x]\n",
    "    return tuple(np.mean(strip, axis=(0, 1)).astype(int))\n",
    "\n",
    "# Get average colors for each layer\n",
    "colors = [\n",
    "    get_layer_color(top_layer_y),    # Top layer (expected red)\n",
    "    get_layer_color(mid_layer_y),    # Middle layer (expected green)\n",
    "    get_layer_color(bottom_layer_y)  # Bottom layer (expected blue)\n",
    "]\n",
    "\n",
    "# Convert to hex codes\n",
    "hex_codes = [f'#{color[0]:02x}{color[1]:02x}{color[2]:02x}' for color in colors]\n",
    "\n",
    "# Print the color codes\n",
    "print(\"Detected colored annotations (3 main layers):\")\n",
    "for i, (rgb, hex_code) in enumerate(zip(colors, hex_codes), 1):\n",
    "    print(f\"Layer {i} (expected {'red' if i==1 else 'green' if i==2 else 'blue'}): RGB = {rgb}, Hex = {hex_code}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
